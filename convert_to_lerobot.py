""" 
è¿™ä¸ªé¡¹ç›®åŸºäºå¼€æºé¡¹ç›® ğŸ¤— LeRobot: https://github.com/huggingface/lerobot 

æˆ‘ä»¬æ„Ÿè°¢ LeRobot å›¢é˜Ÿçš„æ°å‡ºå·¥ä½œå’Œå¯¹ç¤¾åŒºçš„è´¡çŒ®ã€‚

å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œè¯·è€ƒè™‘æ”¯æŒå’Œæ¢ç´¢ LeRobotã€‚
"""

import os
import json
import shutil
import logging
import argparse
from pathlib import Path
from typing import Callable
from functools import partial
from math import ceil
from copy import deepcopy

import h5py
import torch
import einops
import numpy as np
from PIL import Image
from tqdm import tqdm
from pprint import pformat
from tqdm.contrib.concurrent import process_map
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from lerobot.common.datasets.utils import (
    STATS_PATH,
    check_timestamps_sync,
    get_episode_data_index,
    serialize_dict,
    write_json,
)

# å®šä¹‰å„ç§ç›¸æœºå’Œä¼ æ„Ÿå™¨çš„é”®åå¸¸é‡
HEAD_COLOR = "head_color.mp4"
HAND_LEFT_COLOR = "hand_left_color.mp4"
HAND_RIGHT_COLOR = "hand_right_color.mp4"
HEAD_CENTER_FISHEYE_COLOR = "head_center_fisheye_color.mp4"
HEAD_LEFT_FISHEYE_COLOR = "head_left_fisheye_color.mp4"
HEAD_RIGHT_FISHEYE_COLOR = "head_right_fisheye_color.mp4"
BACK_LEFT_FISHEYE_COLOR = "back_left_fisheye_color.mp4"
BACK_RIGHT_FISHEYE_COLOR = "back_right_fisheye_color.mp4"
HEAD_DEPTH = "head_depth"

# é»˜è®¤å›¾åƒå­˜å‚¨è·¯å¾„æ ¼å¼
DEFAULT_IMAGE_PATH = (
    "images/{image_key}/episode_{episode_index:06d}/frame_{frame_index:06d}.jpg"
)

# å®šä¹‰æ•°æ®é›†çš„ç‰¹å¾ç»“æ„ï¼ŒåŒ…æ‹¬å„ç§è§‚æµ‹å’ŒåŠ¨ä½œçš„æ•°æ®ç±»å‹ã€å½¢çŠ¶ç­‰ä¿¡æ¯
FEATURES = {
    "observation.images.top_head": {  # é¡¶éƒ¨å¤´éƒ¨ç›¸æœºå›¾åƒ
        "dtype": "video",  # æ•°æ®ç±»å‹ä¸ºè§†é¢‘
        "shape": [480, 640, 3],  # å›¾åƒå½¢çŠ¶ï¼šé«˜åº¦ã€å®½åº¦ã€é€šé“
        "names": ["height", "width", "channel"],  # ç»´åº¦åç§°
        "video_info": {  # è§†é¢‘ä¿¡æ¯
            "video.fps": 30.0,  # å¸§ç‡
            "video.codec": "av1",  # ç¼–ç æ ¼å¼
            "video.pix_fmt": "yuv420p",  # åƒç´ æ ¼å¼
            "video.is_depth_map": False,  # ä¸æ˜¯æ·±åº¦å›¾
            "has_audio": False,  # æ²¡æœ‰éŸ³é¢‘
        },
    },
    "observation.images.cam_top_depth": {  # é¡¶éƒ¨æ·±åº¦ç›¸æœºå›¾åƒ
        "dtype": "image",  # æ•°æ®ç±»å‹ä¸ºå›¾åƒ
        "shape": [480, 640, 1],  # å›¾åƒå½¢çŠ¶
        "names": ["height", "width", "channel"],
    },
    "observation.images.hand_left": {  # å·¦æ‰‹ç›¸æœºå›¾åƒ
        "dtype": "video",
        "shape": [480, 640, 3],
        "names": ["height", "width", "channel"],
        "video_info": {
            "video.fps": 30.0,
            "video.codec": "av1",
            "video.pix_fmt": "yuv420p",
            "video.is_depth_map": False,
            "has_audio": False,
        },
    },
    "observation.images.hand_right": {  # å³æ‰‹ç›¸æœºå›¾åƒ
        "dtype": "video",
        "shape": [480, 640, 3],
        "names": ["height", "width", "channel"],
        "video_info": {
            "video.fps": 30.0,
            "video.codec": "av1",
            "video.pix_fmt": "yuv420p",
            "video.is_depth_map": False,
            "has_audio": False,
        },
    },
    "observation.images.head_center_fisheye": {  # å¤´éƒ¨ä¸­å¿ƒé±¼çœ¼ç›¸æœº
        "dtype": "video",
        "shape": [748, 960, 3],
        "names": ["height", "width", "channel"],
        "video_info": {
            "video.fps": 30.0,
            "video.codec": "av1",
            "video.pix_fmt": "yuv420p",
            "video.is_depth_map": False,
            "has_audio": False,
        },
    },
    "observation.images.head_left_fisheye": {  # å¤´éƒ¨å·¦ä¾§é±¼çœ¼ç›¸æœº
        "dtype": "video",
        "shape": [748, 960, 3],
        "names": ["height", "width", "channel"],
        "video_info": {
            "video.fps": 30.0,
            "video.codec": "av1",
            "video.pix_fmt": "yuv420p",
            "video.is_depth_map": False,
            "has_audio": False,
        },
    },
    "observation.images.head_right_fisheye": {  # å¤´éƒ¨å³ä¾§é±¼çœ¼ç›¸æœº
        "dtype": "video",
        "shape": [748, 960, 3],
        "names": ["height", "width", "channel"],
        "video_info": {
            "video.fps": 30.0,
            "video.codec": "av1",
            "video.pix_fmt": "yuv420p",
            "video.is_depth_map": False,
            "has_audio": False,
        },
    },
    "observation.images.back_left_fisheye": {  # èƒŒéƒ¨å·¦ä¾§é±¼çœ¼ç›¸æœº
        "dtype": "video",
        "shape": [748, 960, 3],
        "names": ["height", "width", "channel"],
        "video_info": {
            "video.fps": 30.0,
            "video.codec": "av1",
            "video.pix_fmt": "yuv420p",
            "video.is_depth_map": False,
            "has_audio": False,
        },
    },
    "observation.images.back_right_fisheye": {  # èƒŒéƒ¨å³ä¾§é±¼çœ¼ç›¸æœº
        "dtype": "video",
        "shape": [748, 960, 3],
        "names": ["height", "width", "channel"],
        "video_info": {
            "video.fps": 30.0,
            "video.codec": "av1",
            "video.pix_fmt": "yuv420p",
            "video.is_depth_map": False,
            "has_audio": False,
        },
    },
    "observation.state": {  # è§‚æµ‹çŠ¶æ€ï¼ˆæœºå™¨äººçŠ¶æ€ï¼‰
        "dtype": "float32",
        "shape": [20],  # 20ç»´çŠ¶æ€å‘é‡
    },
    "action": {  # åŠ¨ä½œ
        "dtype": "float32",
        "shape": [22],  # 22ç»´åŠ¨ä½œå‘é‡
    },
    "episode_index": {  # å›åˆç´¢å¼•
        "dtype": "int64",
        "shape": [1],
        "names": None,
    },
    "frame_index": {  # å¸§ç´¢å¼•
        "dtype": "int64",
        "shape": [1],
        "names": None,
    },
    "index": {  # å…¨å±€ç´¢å¼•
        "dtype": "int64",
        "shape": [1],
        "names": None,
    },
    "task_index": {  # ä»»åŠ¡ç´¢å¼•
        "dtype": "int64",
        "shape": [1],
        "names": None,
    },
}


def get_stats_einops_patterns(dataset, num_workers=0):
    """è¿™äº›einopsæ¨¡å¼å°†ç”¨äºèšåˆæ‰¹æ¬¡å¹¶è®¡ç®—ç»Ÿè®¡æ•°æ®ã€‚

    æ³¨æ„ï¼šæˆ‘ä»¬å‡è®¾å›¾åƒæ˜¯é€šé“ä¼˜å…ˆæ ¼å¼
    """

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = torch.utils.data.DataLoader(
        dataset,
        num_workers=num_workers,
        batch_size=2,
        shuffle=False,
    )
    batch = next(iter(dataloader))  # è·å–ä¸€ä¸ªæ‰¹æ¬¡æ•°æ®

    stats_patterns = {}  # å­˜å‚¨æ¯ç§ç‰¹å¾çš„ç»Ÿè®¡æ¨¡å¼

    for key in dataset.features:
        # æ£€æŸ¥å¼ é‡ä¸æ˜¯float64ç±»å‹
        assert batch[key].dtype != torch.float64

        # å¦‚æœæ˜¯ç›¸æœºå›¾åƒæ•°æ®
        if key in dataset.meta.camera_keys:
            # æ£€æŸ¥å›¾åƒæ˜¯é€šé“ä¼˜å…ˆæ ¼å¼
            _, c, h, w = batch[key].shape
            assert (
                c < h and c < w
            ), f"æœŸæœ›é€šé“ä¼˜å…ˆå›¾åƒï¼Œä½†å¾—åˆ° {batch[key].shape}"
            assert (
                batch[key].dtype == torch.float32
            ), f"æœŸæœ› torch.float32ï¼Œä½†å¾—åˆ° {batch[key].dtype=}"
            # è®¾ç½®å›¾åƒæ•°æ®çš„ç»Ÿè®¡æ¨¡å¼
            stats_patterns[key] = "b c h w -> c 1 1"
        elif batch[key].ndim == 2:  # äºŒç»´æ•°æ®
            stats_patterns[key] = "b c -> c "
        elif batch[key].ndim == 1:  # ä¸€ç»´æ•°æ®
            stats_patterns[key] = "b -> 1"
        else:
            raise ValueError(f"{key}, {batch[key].shape}")

    return stats_patterns


def compute_stats(dataset, batch_size=8, num_workers=4, max_num_samples=None):
    """è®¡ç®—LeRobotDatasetä¸­æ‰€æœ‰æ•°æ®é”®çš„å‡å€¼/æ ‡å‡†å·®å’Œæœ€å°å€¼/æœ€å¤§å€¼ç»Ÿè®¡ä¿¡æ¯ã€‚"""
    if max_num_samples is None:
        max_num_samples = len(dataset)

    # è·å–ç»Ÿè®¡æ¨¡å¼
    stats_patterns = get_stats_einops_patterns(dataset, num_workers)

    # åˆå§‹åŒ–ç»Ÿè®¡é‡ï¼šå‡å€¼ã€æ ‡å‡†å·®ã€æœ€å¤§å€¼ã€æœ€å°å€¼
    mean, std, max, min = {}, {}, {}, {}
    for key in stats_patterns:
        mean[key] = torch.tensor(0.0).float()
        std[key] = torch.tensor(0.0).float()
        max[key] = torch.tensor(-float("inf")).float()
        min[key] = torch.tensor(float("inf")).float()

    def create_seeded_dataloader(dataset, batch_size, seed):
        """åˆ›å»ºå¸¦æœ‰å›ºå®šç§å­çš„æ•°æ®åŠ è½½å™¨ï¼Œç¡®ä¿å¯é‡å¤æ€§"""
        generator = torch.Generator()
        generator.manual_seed(seed)
        dataloader = torch.utils.data.DataLoader(
            dataset,
            num_workers=num_workers,
            batch_size=batch_size,
            shuffle=True,
            drop_last=False,
            generator=generator,
        )
        return dataloader

    # è®¡ç®—å‡å€¼å’Œæœ€å°/æœ€å¤§å€¼
    first_batch = None  # ä¿å­˜ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ç”¨äºéªŒè¯
    running_item_count = 0  # ç”¨äºåœ¨çº¿å‡å€¼è®¡ç®—
    dataloader = create_seeded_dataloader(dataset, batch_size, seed=1337)
    for i, batch in enumerate(
        tqdm(
            dataloader,
            total=ceil(max_num_samples / batch_size),
            desc="Compute mean, min, max",
        )
    ):
        this_batch_size = len(batch["index"])
        running_item_count += this_batch_size
        if first_batch is None:
            first_batch = deepcopy(batch)  # ä¿å­˜ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        for key, pattern in stats_patterns.items():
            batch[key] = batch[key].float()
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„å‡å€¼
            batch_mean = einops.reduce(batch[key], pattern, "mean")
            # ä½¿ç”¨æ•°å€¼ç¨³å®šçš„æ–¹å¼æ›´æ–°å‡å€¼ï¼šxÌ„â‚™ = xÌ„â‚™â‚‹â‚ + Bâ‚™ * (xâ‚™ - xÌ„â‚™â‚‹â‚) / Nâ‚™
            mean[key] = (
                mean[key]
                + this_batch_size * (batch_mean - mean[key]) / running_item_count
            )
            # æ›´æ–°æœ€å¤§å€¼å’Œæœ€å°å€¼
            max[key] = torch.maximum(
                max[key], einops.reduce(batch[key], pattern, "max")
            )
            min[key] = torch.minimum(
                min[key], einops.reduce(batch[key], pattern, "min")
            )

        if i == ceil(max_num_samples / batch_size) - 1:
            break

    # è®¡ç®—æ ‡å‡†å·®
    first_batch_ = None
    running_item_count = 0  # ç”¨äºåœ¨çº¿æ ‡å‡†å·®è®¡ç®—
    dataloader = create_seeded_dataloader(dataset, batch_size, seed=1337)
    for i, batch in enumerate(
        tqdm(dataloader, total=ceil(max_num_samples / batch_size), desc="Compute std")
    ):
        this_batch_size = len(batch["index"])
        running_item_count += this_batch_size
        # æ£€æŸ¥æ‰¹æ¬¡é¡ºåºæ˜¯å¦ä¸ä¹‹å‰ç›¸åŒ
        if first_batch_ is None:
            first_batch_ = deepcopy(batch)
            for key in stats_patterns:
                assert torch.equal(first_batch_[key], first_batch[key])
        for key, pattern in stats_patterns.items():
            batch[key] = batch[key].float()
            # è®¡ç®—å¹³æ–¹æ®‹å·®çš„å‡å€¼
            batch_std = einops.reduce((batch[key] - mean[key]) ** 2, pattern, "mean")
            # æ›´æ–°æ ‡å‡†å·®
            std[key] = (
                std[key] + this_batch_size * (batch_std - std[key]) / running_item_count
            )

        if i == ceil(max_num_samples / batch_size) - 1:
            break

    # è®¡ç®—æœ€ç»ˆçš„æ ‡å‡†å·®ï¼ˆå¹³æ–¹æ ¹ï¼‰
    for key in stats_patterns:
        std[key] = torch.sqrt(std[key])

    # ç»„ç»‡ç»Ÿè®¡ç»“æœ
    stats = {}
    for key in stats_patterns:
        stats[key] = {
            "mean": mean[key],
            "std": std[key],
            "max": max[key],
            "min": min[key],
        }
    return stats


class AgiBotDataset(LeRobotDataset):
    """AgiBotæ•°æ®é›†ç±»ï¼Œç»§æ‰¿è‡ªLeRobotDataset"""
    
    def __init__(
        self,
        repo_id: str,
        root: str | Path | None = None,
        episodes: list[int] | None = None,
        image_transforms: Callable | None = None,
        delta_timestamps: dict[list[float]] | None = None,
        tolerance_s: float = 1e-4,
        download_videos: bool = True,
        local_files_only: bool = False,
        video_backend: str | None = None,
    ):
        super().__init__(
            repo_id=repo_id,
            root=root,
            episodes=episodes,
            image_transforms=image_transforms,
            delta_timestamps=delta_timestamps,
            tolerance_s=tolerance_s,
            download_videos=download_videos,
            local_files_only=local_files_only,
            video_backend=video_backend,
        )

    def save_episode(
        self, task: str, episode_data: dict | None = None, videos: dict | None = None
    ) -> None:
        """
        æˆ‘ä»¬é‡å†™æ­¤æ–¹æ³•ä»¥å°†mp4è§†é¢‘å¤åˆ¶åˆ°ç›®æ ‡ä½ç½®
        """
        if not episode_data:
            episode_buffer = self.episode_buffer

        episode_length = episode_buffer.pop("size")  # è·å–å›åˆé•¿åº¦
        episode_index = episode_buffer["episode_index"]  # è·å–å›åˆç´¢å¼•
        if episode_index != self.meta.total_episodes:
            # TODO(aliberts): æ·»åŠ ä½¿ç”¨ç°æœ‰episode_indexçš„é€‰é¡¹
            raise NotImplementedError(
                "æ‚¨å¯èƒ½æ‰‹åŠ¨æä¾›äº†episode_bufferï¼Œä½†å…¶episode_indexä¸æ•°æ®é›†ä¸­çš„æ€»å›åˆæ•°ä¸åŒ¹é…ã€‚ç›®å‰ä¸æ”¯æŒæ­¤æ“ä½œã€‚"
            )

        if episode_length == 0:
            raise ValueError(
                "åœ¨è°ƒç”¨`add_episode`ä¹‹å‰ï¼Œå¿…é¡»ä½¿ç”¨`add_frame`æ·»åŠ ä¸€ä¸ªæˆ–å¤šä¸ªå¸§ã€‚"
            )

        task_index = self.meta.get_task_index(task)  # è·å–ä»»åŠ¡ç´¢å¼•

        print(f"[save_episode][episode_buffer.keys()] {episode_buffer.keys()}")
        print(f"[save_episode][self.features] {self.features}")
        # ğŸ‘‡ åœ¨è¿™é‡Œç§»é™¤ 'task'ï¼Œå› ä¸ºå®ƒä¸æ˜¯ features çš„ä¸€éƒ¨åˆ†
        if 'task' in episode_buffer:
            episode_buffer.pop('task')

        # æ£€æŸ¥ç¼“å†²åŒºé”®æ˜¯å¦ä¸ç‰¹å¾åŒ¹é…
        if not set(episode_buffer.keys()) == set(self.features):
            raise ValueError()

        # å¤„ç†æ¯ä¸ªç‰¹å¾çš„æ•°æ®
        for key, ft in self.features.items():
            if key == "index":
                # ç”Ÿæˆå…¨å±€ç´¢å¼•
                episode_buffer[key] = np.arange(
                    self.meta.total_frames, self.meta.total_frames + episode_length
                )
            elif key == "episode_index":
                # å¡«å……å›åˆç´¢å¼•
                episode_buffer[key] = np.full((episode_length,), episode_index)
            elif key == "task_index":
                # å¡«å……ä»»åŠ¡ç´¢å¼•
                episode_buffer[key] = np.full((episode_length,), task_index)
            elif ft["dtype"] in ["image", "video"]:
                # è·³è¿‡å›¾åƒå’Œè§†é¢‘æ•°æ®ï¼Œå®ƒä»¬å·²ç»å•ç‹¬å¤„ç†
                continue
            elif len(ft["shape"]) == 1 and ft["shape"][0] == 1:
                # å¤„ç†ä¸€ç»´æ ‡é‡æ•°æ®
                episode_buffer[key] = np.array(episode_buffer[key], dtype=ft["dtype"])
            elif len(ft["shape"]) == 1 and ft["shape"][0] > 1:
                # å¤„ç†ä¸€ç»´å‘é‡æ•°æ®
                episode_buffer[key] = np.stack(episode_buffer[key])
            else:
                raise ValueError(key)

        self._wait_image_writer()  # ç­‰å¾…å›¾åƒå†™å…¥å®Œæˆ
        self._save_episode_table(episode_buffer, episode_index)  # ä¿å­˜å›åˆæ•°æ®è¡¨

        # ä¿å­˜å…ƒæ•°æ®
        self.meta.save_episode(episode_index, episode_length, task, task_index)
        
        # å¤„ç†è§†é¢‘æ–‡ä»¶
        for key in self.meta.video_keys:
            video_path = self.root / self.meta.get_video_file_path(episode_index, key)
            episode_buffer[key] = video_path
            video_path.parent.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•
            shutil.copyfile(videos[key], video_path)  # å¤åˆ¶è§†é¢‘æ–‡ä»¶
            print(f"[save_episode][key] {key}, video_path: {video_path}, videos[key]: {videos[key]}")
        
        if not episode_data:  # é‡ç½®ç¼“å†²åŒº
            self.episode_buffer = self.create_episode_buffer()
        self.consolidated = False  # æ ‡è®°ä¸ºæœªæ•´åˆ

    def consolidate(
        self, run_compute_stats: bool = True, keep_image_files: bool = False
    ) -> None:
        """æ•´åˆæ•°æ®é›†ï¼Œè®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        self.hf_dataset = self.load_hf_dataset()  # åŠ è½½HuggingFaceæ•°æ®é›†
        self.episode_data_index = get_episode_data_index(
            self.meta.episodes, self.episodes
        )
        # æ£€æŸ¥æ—¶é—´æˆ³åŒæ­¥
        check_timestamps_sync(
            self.hf_dataset, self.episode_data_index, self.fps, self.tolerance_s
        )
        
        # å†™å…¥è§†é¢‘ä¿¡æ¯
        if len(self.meta.video_keys) > 0:
            self.meta.write_video_info()

        # æ¸…ç†å›¾åƒæ–‡ä»¶ï¼ˆå¦‚æœä¸ä¿ç•™ï¼‰
        if not keep_image_files:
            img_dir = self.root / "images"
            if img_dir.is_dir():
                shutil.rmtree(self.root / "images")
                
        # éªŒè¯è§†é¢‘æ–‡ä»¶æ•°é‡
        video_files = list(self.root.rglob("*.mp4"))
        assert len(video_files) == self.num_episodes * len(self.meta.video_keys)

        # éªŒè¯parquetæ–‡ä»¶æ•°é‡
        parquet_files = list(self.root.rglob("*.parquet"))
        assert len(parquet_files) == self.num_episodes

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if run_compute_stats:
            self.stop_image_writer()  # åœæ­¢å›¾åƒå†™å…¥å™¨
            self.meta.stats = compute_stats(self)  # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            serialized_stats = serialize_dict(self.meta.stats)  # åºåˆ—åŒ–ç»Ÿè®¡ä¿¡æ¯
            write_json(serialized_stats, self.root / STATS_PATH)  # å†™å…¥ç»Ÿè®¡æ–‡ä»¶
            self.consolidated = True  # æ ‡è®°ä¸ºå·²æ•´åˆ
        else:
            logging.warning(
                "è·³è¿‡æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯çš„è®¡ç®—ï¼Œæ•°æ®é›†æœªå®Œå…¨æ•´åˆã€‚"
            )

    def add_frame(self, frame: dict) -> None:
        """
        æ­¤å‡½æ•°ä»…å°†å¸§æ·»åŠ åˆ°episode_bufferä¸­ã€‚é™¤äº†å›¾åƒï¼ˆå†™å…¥ä¸´æ—¶ç›®å½•ï¼‰ä¹‹å¤–ï¼Œä¸ä¼šå†™å…¥ç£ç›˜ã€‚
        è¦ä¿å­˜è¿™äº›å¸§ï¼Œéœ€è¦è°ƒç”¨'save_episode()'æ–¹æ³•ã€‚
        """
        # TODO(aliberts, rcadene): æ·»åŠ è¾“å…¥æ£€æŸ¥ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºnumpyæˆ–torchï¼Œæ£€æŸ¥dtypeå’Œshapeæ˜¯å¦åŒ¹é…ç­‰ã€‚

        if self.episode_buffer is None:
            self.episode_buffer = self.create_episode_buffer()  # åˆ›å»ºç¼“å†²åŒº

        frame_index = self.episode_buffer["size"]  # è·å–å½“å‰å¸§ç´¢å¼•
        timestamp = (
            frame.pop("timestamp") if "timestamp" in frame else frame_index / self.fps
        )  # è·å–æˆ–è®¡ç®—æ—¶é—´æˆ³
        self.episode_buffer["frame_index"].append(frame_index)  # æ·»åŠ å¸§ç´¢å¼•
        self.episode_buffer["timestamp"].append(timestamp)  # æ·»åŠ æ—¶é—´æˆ³

        # å¤„ç†å¸§ä¸­çš„æ¯ä¸ªæ•°æ®é¡¹
        for key in frame:
            if key not in self.features:
                raise ValueError(key)
            # å°†torchå¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„
            item = (
                frame[key].numpy()
                if isinstance(frame[key], torch.Tensor)
                else frame[key]
            )
            self.episode_buffer[key].append(item)  # æ·»åŠ åˆ°ç¼“å†²åŒº

        self.episode_buffer["size"] += 1  # å¢åŠ ç¼“å†²åŒºå¤§å°


def load_depths(root_dir: str, camera_name: str):
    """åŠ è½½æ·±åº¦å›¾åƒæ•°æ®"""
    cam_path = Path(root_dir)
    all_imgs = sorted(list(cam_path.glob(f"{camera_name}*")))  # è·å–æ‰€æœ‰æ·±åº¦å›¾åƒæ–‡ä»¶
    # åŠ è½½å¹¶å½’ä¸€åŒ–æ·±åº¦å›¾åƒï¼ˆé™¤ä»¥1000å°†æ¯«ç±³è½¬æ¢ä¸ºç±³ï¼‰
    return [np.array(Image.open(f)).astype(np.float32) / 1000 for f in all_imgs]


def load_local_dataset(episode_id: int, src_path: str, task_id: int) -> list | None:
    """åŠ è½½æœ¬åœ°æ•°æ®é›†å¹¶è¿”å›åŒ…å«è§‚æµ‹å’ŒåŠ¨ä½œçš„å­—å…¸"""

    ob_dir = Path(src_path) / f"observations/{task_id}/{episode_id}"  # è§‚æµ‹æ•°æ®ç›®å½•
    depth_imgs = load_depths(ob_dir / "depth", HEAD_DEPTH)  # åŠ è½½æ·±åº¦å›¾åƒ
    proprio_dir = Path(src_path) / f"proprio_stats/{task_id}/{episode_id}"  # æœ¬ä½“æ„ŸçŸ¥æ•°æ®ç›®å½•

    # ä»HDF5æ–‡ä»¶åŠ è½½æœ¬ä½“æ„ŸçŸ¥æ•°æ®
    with h5py.File(proprio_dir / "proprio_stats.h5") as f:
        state_joint = np.array(f["state/joint/position"])  # å…³èŠ‚ä½ç½®çŠ¶æ€
        state_effector = np.array(f["state/effector/position"])  # æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®çŠ¶æ€
        state_head = np.array(f["state/head/position"])  # å¤´éƒ¨ä½ç½®çŠ¶æ€
        state_waist = np.array(f["state/waist/position"])  # è…°éƒ¨ä½ç½®çŠ¶æ€
        action_joint = np.array(f["action/joint/position"])  # å…³èŠ‚åŠ¨ä½œ
        action_effector = np.array(f["action/effector/position"])  # æœ«ç«¯æ‰§è¡Œå™¨åŠ¨ä½œ
        action_head = np.array(f["action/head/position"])  # å¤´éƒ¨åŠ¨ä½œ
        action_waist = np.array(f["action/waist/position"])  # è…°éƒ¨åŠ¨ä½œ
        action_velocity = np.array(f["action/robot/velocity"])  # æœºå™¨äººé€Ÿåº¦åŠ¨ä½œ

    # åˆå¹¶çŠ¶æ€æ•°æ®
    states_value = np.hstack(
        [state_joint, state_effector, state_head, state_waist]
    ).astype(np.float32)
    
    # æ£€æŸ¥åŠ¨ä½œæ•°æ®ä¸€è‡´æ€§
    assert (
        action_joint.shape[0] == action_effector.shape[0]
    ), f"action_jointå½¢çŠ¶:{action_joint.shape};action_effectorå½¢çŠ¶:{action_effector.shape}"
    
    # åˆå¹¶åŠ¨ä½œæ•°æ®
    action_value = np.hstack(
        [action_joint, action_effector, action_head, action_waist, action_velocity]
    ).astype(np.float32)

    # æ£€æŸ¥æ•°æ®é•¿åº¦ä¸€è‡´æ€§
    assert len(depth_imgs) == len(
        states_value
    ), f"å›¾åƒæ•°é‡å’ŒçŠ¶æ€æ•°é‡ä¸ç›¸ç­‰"
    assert len(depth_imgs) == len(
        action_value
    ), f"å›¾åƒæ•°é‡å’ŒåŠ¨ä½œæ•°é‡ä¸ç›¸ç­‰"
    
    # æ„å»ºå¸§æ•°æ®åˆ—è¡¨
    frames = [
        {
            "observation.images.cam_top_depth": depth_imgs[i],  # æ·±åº¦å›¾åƒ
            "observation.state": states_value[i],  # çŠ¶æ€
            "action": action_value[i],  # åŠ¨ä½œ
        }
        for i in range(len(depth_imgs))
    ]

    # æ„å»ºè§†é¢‘æ–‡ä»¶è·¯å¾„å­—å…¸
    v_path = ob_dir / "videos"
    videos = {
        "observation.images.top_head": v_path / HEAD_COLOR,
        "observation.images.hand_left": v_path / HAND_LEFT_COLOR,
        "observation.images.hand_right": v_path / HAND_RIGHT_COLOR,
        "observation.images.head_center_fisheye": v_path / HEAD_CENTER_FISHEYE_COLOR,
        "observation.images.head_left_fisheye": v_path / HEAD_LEFT_FISHEYE_COLOR,
        "observation.images.head_right_fisheye": v_path / HEAD_RIGHT_FISHEYE_COLOR,
        "observation.images.back_left_fisheye": v_path / BACK_LEFT_FISHEYE_COLOR,
        "observation.images.back_right_fisheye": v_path / BACK_RIGHT_FISHEYE_COLOR,
    }
    return frames, videos


def get_task_instruction(task_json_path: str) -> dict:
    """è·å–ä»»åŠ¡è¯­è¨€æŒ‡ä»¤"""
    with open(task_json_path, "r") as f:
        task_info = json.load(f)  # åŠ è½½ä»»åŠ¡ä¿¡æ¯
    task_name = task_info[0]["task_name"]  # è·å–ä»»åŠ¡åç§°
    task_init_scene = task_info[0]["init_scene_text"]  # è·å–åˆå§‹åœºæ™¯æè¿°
    task_instruction = f"{task_name}.{task_init_scene}"  # ç»„åˆä»»åŠ¡æŒ‡ä»¤
    print(f"è·å–ä»»åŠ¡æŒ‡ä»¤ <{task_instruction}>")
    return task_instruction


def main(
    src_path: str,
    tgt_path: str,
    task_id: int,
    repo_id: str,
    task_info_json: str,
    debug: bool = False,
):
    """ä¸»å‡½æ•°ï¼šå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºLeRobotæ ¼å¼çš„æ•°æ®é›†"""
    task_name = get_task_instruction(task_info_json)  # è·å–ä»»åŠ¡æŒ‡ä»¤

    # åˆ›å»ºAgiBotæ•°æ®é›†
    dataset = AgiBotDataset.create(
        repo_id=repo_id,
        root=f"{tgt_path}/{repo_id}",
        fps=30,  # å¸§ç‡
        robot_type="a2d",  # æœºå™¨äººç±»å‹
        features=FEATURES,  # ç‰¹å¾å®šä¹‰
    )

    # è·å–æ‰€æœ‰è§‚æµ‹æ•°æ®å­ç›®å½•
    all_subdir = sorted(
        [
            f.as_posix()
            for f in Path(src_path).glob(f"observations/{task_id}/*")
            if f.is_dir()
        ]
    )

    if debug:
        all_subdir = all_subdir[:2]  # è°ƒè¯•æ¨¡å¼ä¸‹åªå¤„ç†å‰2ä¸ªç›®å½•

    # è·å–æ‰€æœ‰å›åˆID
    all_subdir_eids = [int(Path(path).name) for path in all_subdir]

    # åŠ è½½æ‰€æœ‰æœ¬åœ°æ•°æ®é›†
    if debug:
        # è°ƒè¯•æ¨¡å¼ä¸‹é¡ºåºå¤„ç†
        raw_datasets_before_filter = [
            load_local_dataset(subdir, src_path=src_path, task_id=task_id)
            for subdir in tqdm(all_subdir_eids)
        ]
    else:
        # ç”Ÿäº§ç¯å¢ƒä¸‹ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†
        raw_datasets_before_filter = process_map(
            partial(load_local_dataset, src_path=src_path, task_id=task_id),
            all_subdir_eids,
            max_workers=os.cpu_count() // 2,  # ä½¿ç”¨ä¸€åŠCPUæ ¸å¿ƒ
            desc="Generating local dataset",
        )
        
    # ç§»é™¤ç»“æœä¸ºNoneçš„æ•°æ®é›†
    raw_datasets = [
        dataset for dataset in raw_datasets_before_filter if dataset is not None
    ]

    # ç§»é™¤å¯¹åº”å­ç›®å½•ID
    all_subdir_eids = [
        eid
        for eid, dataset in zip(all_subdir_eids, raw_datasets_before_filter)
        if dataset is not None
    ]
    
    # ç”Ÿæˆä»»åŠ¡æè¿°åˆ—è¡¨
    all_subdir_episode_desc = [task_name] * len(all_subdir_eids)
    print(all_subdir_episode_desc)

    # å°†åŸå§‹æ•°æ®æ·»åŠ åˆ°æ•°æ®é›†ä¸­
    for raw_dataset, episode_desc in zip(
        tqdm(raw_datasets, desc="Generating dataset from raw datasets"),
        all_subdir_episode_desc,
    ):
        # æ·»åŠ æ¯ä¸ªå¸§åˆ°æ•°æ®é›†
        for raw_dataset_sub in tqdm(
            raw_dataset[0], desc="Generating dataset from raw dataset"
        ):
            dataset.add_frame(raw_dataset_sub)
        # ä¿å­˜å›åˆæ•°æ®
        dataset.save_episode(task=episode_desc, videos=raw_dataset[1])
        
    # æ•´åˆæ•°æ®é›†
    dataset.consolidate()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()  # åˆ›å»ºå‚æ•°è§£æå™¨
    parser.add_argument(
        "--src_path",
        type=str,
        required=True,
        help="æºæ•°æ®è·¯å¾„"
    )
    parser.add_argument(
        "--task_id",
        type=str,
        required=True,
        help="ä»»åŠ¡ID"
    )
    parser.add_argument(
        "--tgt_path",
        type=str,
        required=True,
        help="ç›®æ ‡æ•°æ®è·¯å¾„"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="è°ƒè¯•æ¨¡å¼"
    )
    args = parser.parse_args()  # è§£æå‚æ•°

    task_id = args.task_id
    json_file = f"{args.src_path}/task_info/task_{args.task_id}.json"  # ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶è·¯å¾„
    dataset_base = f"agibotworld/task_{args.task_id}"  # æ•°æ®é›†åŸºç¡€åç§°

    assert Path(json_file).exists, f"æ‰¾ä¸åˆ° {json_file}ã€‚"  # æ£€æŸ¥ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    
    # è¿è¡Œä¸»å‡½æ•°
    main(args.src_path, args.tgt_path, task_id, dataset_base, json_file, args.debug)